# Session Consumption vs. “Network Disabled”
## Clarifying Boundary-Obscuring UX and Silent Vision Failures in Multimodal LLMs

---

## Summary

During PDF-to-text workflows using multimodal LLMs, users may encounter messaging such as:

> “The network is disabled, but since the PDF content is already in the context, I will proceed…”

At the same time, they may observe:
- Rapid session consumption
- Exhaustion of image/vision limits
- Inconsistent handling of image-based PDFs (OCR sometimes performed, sometimes skipped)

This document explains **why these behaviors occur**, why the terminology is **intentionally but problematically ambiguous**, and why certain cases constitute **silent partial failures** rather than transparent errors.

---

## Key Observations

1. Session limits can be heavily consumed even when:
   - No external network access is used
   - All inputs are already provided by the user

2. Image-based PDFs may:
   - Be correctly identified as images
   - Consume vision-related resources
   - Yet fail to undergo OCR without explicit error reporting

3. Users are not informed whether:
   - OCR was attempted
   - OCR failed
   - GPU / vision budget limits were the cause

---

## Root Cause Analysis

### 1. “Network Disabled” Is a Policy Boundary, Not a Resource Boundary

The phrase **“network disabled”** means:
- No web browsing
- No external API calls
- No retrieval of new external data

It does **not** mean:
- Reduced computation
- Reduced session usage
- Reduced GPU or vision cost

This wording serves as a **responsibility disclaimer**, not a **resource usage indicator**.

---

### 2. Session Consumption Is Dominated by Vision Processing

When PDFs are processed as images:

- Vision tokens are consumed (significantly more expensive than text tokens)
- GPU-intensive visual inference is performed
- Each page is processed independently
- No semantic caching is reused across sessions

As a result:

> External network usage = 0  
> Vision computation cost = high

These two dimensions are orthogonal.

---

### 3. “Already in Context” Is Session-Scoped, Not Persistent

“Already in context” means:
- Data exists only within the current conversation session
- Once the session resets, all image understanding must be redone
- Vision processing costs are re-incurred from scratch

Thus, image-heavy workflows are inherently session-expensive.

---

## Addendum: Silent OCR Fallback Under Vision Budget Limits

### Observed Behavior

In some cases:
- Image-based PDFs are correctly recognized as images
- Vision resources are consumed to identify document structure
- OCR is **not performed**
- The system silently falls back to text-only handling (or partial processing)

This occurs without:
- Explicit error messages
- Clear indication of GPU / vision budget exhaustion
- Disclosure that OCR was skipped

---

### Likely Execution Path

1. **Image detection phase succeeds**
   - Vision model processes pages
   - Image tokens are consumed
   - Session budget is reduced

2. **OCR phase is blocked**
   - GPU or vision quota is insufficient
   - High-cost visual-to-text conversion is skipped

3. **Silent fallback occurs**
   - No hard failure is reported
   - User receives text-only output
   - The cost has already been incurred

This results in **cost without corresponding functionality**.

---

### Why This Is Problematic

From an engineering and QA perspective, this is a failure mode characterized by:

- Partial execution
- Non-atomic behavior
- Missing failure signaling

Specifically:

- ❌ OCR capability unavailable
- ❌ No explicit failure notification
- ⭕ Vision cost already incurred

This violates a fundamental expectation:

> **If a resource-intensive preflight step consumes cost,  
> execution failure should be explicit.**

---

## Why This Is an Edge Case

For most users:
- The distinction between vision detection and OCR execution is invisible
- “It worked” or “It didn’t” is sufficient

For system-aware users:
- Resource usage is tracked
- Failure modes are expected to be observable
- Cost–result mismatches are unacceptable

Thus, this issue is:
- ❌ Not a functional bug
- ❌ Not a policy violation
- ❌ Not a security issue

It is:
- ✅ An intentional abstraction
- ⚠️ A design-level edge case
- ⚠️ A case of **silent partial failure under resource constraints**

---

## Design Assessment

This behavior represents a tradeoff:

- UX simplicity over precision
- Responsibility disclaimers over cost transparency

However, it introduces ambiguity by:
- Using a single term (“network”) to cover policy boundaries
- Omitting any signal about computational or vision limits
- Allowing cost-incurring steps to fail silently

---

## Why This Matters

Without clarification:
- Users may unknowingly burn session limits
- Root causes of failure remain opaque
- Frustration accumulates without actionable feedback

From an engineering standpoint:

> **Opaque cost attribution is worse than high cost.**

Clear failure signaling enables informed decisions.
Silent fallback does not.

---

## Conclusion

The phrase “network disabled” functions as a **policy boundary marker**, not a **resource usage indicator**.

Combined with silent OCR fallback under vision budget constraints, it creates a boundary mismatch that only surfaces in edge cases — but those edge cases matter.

This document exists to make that mismatch explicit.

---

## One-Line Takeaway

> **Session cost is driven by vision computation, not network access.  
> Silent OCR fallback under GPU limits creates cost–result mismatches that should be explicit.**
